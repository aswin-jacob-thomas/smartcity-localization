{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift\n",
    "import utm\n",
    "from sklearn.cluster import MeanShift\n",
    "import statistics \n",
    "from statistics import mode \n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import geocoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Process, Pipe\n",
    "import urllib.request\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel(b2, p, cluster_id, cluster_array,cordinate_array, zone_array, data_array, conn):\n",
    "    current_cluster_result = {}\n",
    "    \n",
    "    len_of_cluster = len(cluster_array)\n",
    "    compass_array = cluster_array[:,[2]]\n",
    "    a = np.tan(np.radians(90-compass_array))\n",
    "    b = np.ones(np.shape(compass_array))\n",
    "    c = np.multiply(a,cluster_array[:,[0]]) - cluster_array[:,[1]]\n",
    "    eq_coeff_cluster = np.hstack((a, -b ,c))\n",
    "    # we take the value of p as 300 just for analysing the time taken to run this\n",
    "    # Creating lines from the compass and the current point\n",
    "    # Initializing the intersection of lines numpy array\n",
    "    pairwise_indices = np.random.randint(0, len_of_cluster , (p,2))\n",
    "    pairs = eq_coeff_cluster[pairwise_indices]\n",
    "\n",
    "    A = pairs[:,:,:-1]\n",
    "    Y = pairs[:,:,-1:]\n",
    "    intersections_of_lines = np.squeeze(np.matmul(np.linalg.pinv(A),  Y))\n",
    "    ms = MeanShift(bandwidth=b2)  \n",
    "    labels = (ms.fit_predict(intersections_of_lines)).tolist()\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "    end = time.time()\n",
    "\n",
    "    mode_of_labels = max(set(labels), key=labels.count)\n",
    "    current_cluster_result['cluster_id'] = cluster_id\n",
    "    current_cluster_result['cluster_item_count'] = len_of_cluster       \n",
    "    \n",
    "    cordinate_list = (cordinate_array).tolist()\n",
    "    cordinate = max(set(cordinate_list), key=cordinate_list.count)\n",
    "\n",
    "    zone_list = (zone_array).tolist()\n",
    "    zone = max(set(zone_list), key=zone_list.count)\n",
    "    lat_long = utm.to_latlon(cluster_centers[mode_of_labels][0], cluster_centers[mode_of_labels][1], cordinate, zone)\n",
    "\n",
    "    current_cluster_result['cluster_latitude'] = lat_long[0]\n",
    "    current_cluster_result['cluster_longitude'] = lat_long[1]\n",
    "    current_cluster_result['cluster_objects'] = (data_array).tolist()\n",
    "    conn.send(current_cluster_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_remote_url(url, conn):\n",
    "    response = urllib.request.urlopen(url).read()\n",
    "    json_data = json.loads(response)\n",
    "    data = json_data['data']\n",
    "    conn.send(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lambda_handler(b1 = 50, b2 = 150, p = 250):\n",
    "    processes = []\n",
    "    parent_connections = []\n",
    "    \n",
    "    parent1, child1 = Pipe()\n",
    "    parent2, child2 = Pipe()\n",
    "    \n",
    "    parent_connections.append(parent1)\n",
    "    parent_connections.append(parent2)\n",
    "    \n",
    "    p1 = Process(target=read_remote_url, args=('http://backend.digitaltwincities.info', child1))\n",
    "    p2 = Process(target=read_remote_url, args=('http://backend.digitaltwincities.info/poles', child2))\n",
    "    \n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    \n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "    data = parent1.recv()\n",
    "    poles_data = parent2.recv()\n",
    "    array = []\n",
    "    # Creating image array which contains all the images\n",
    "    data_array = []\n",
    "    # Creating a cordinate array which contains all the coordinates\n",
    "    cordinate_array = []\n",
    "\n",
    "    zone_array = []\n",
    "\n",
    "    for d in data:\n",
    "        ut_cordinates = utm.from_latlon(d['latitude'], d['longitude'])\n",
    "        t_list = [ut_cordinates[0],ut_cordinates[1],d['compass']+2.28]\n",
    "        data_array.append(d)\n",
    "        cordinate_array.append(ut_cordinates[2])\n",
    "        zone_array.append(ut_cordinates[3])\n",
    "        array.append(t_list)\n",
    "    array = np.array(array)\n",
    "    data_array = np.array(data_array)\n",
    "    cordinate_array = np.array(cordinate_array)\n",
    "    zone_array = np.array(zone_array)\n",
    "\n",
    "    # Now the array will have latitude, longitude and compass as its columns\n",
    "    X = array[:,[0,1]]\n",
    "    # Now X will have only latitude and longitude values. Performing mean shift algorithm on the latitude and longitudes\n",
    "    ms = MeanShift(bandwidth=b1)\n",
    "    labels = ms.fit_predict(X)\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "    labels = np.vstack(labels)\n",
    "    \n",
    "    array = np.hstack((array,labels))\n",
    "    # Stacking the labels next to array. Now array contains latitude, longitude, compass, label\n",
    "    \n",
    "    return_value = []\n",
    "    processes = []\n",
    "    parent_connections = []\n",
    "    \n",
    "    for cluster in range(len(cluster_centers)):\n",
    "        \n",
    "        indices_of_cluster = np.where(array[:,3] == cluster)\n",
    "        cluster_array = array[indices_of_cluster]  \n",
    "        len_of_cluster = len(cluster_array)\n",
    "        if len_of_cluster < 2:\n",
    "            continue\n",
    "        parent_conn, child_conn = Pipe()\n",
    "        parent_connections.append(parent_conn)\n",
    "        \n",
    "        process = Process(target=parallel, args=(b2, p , cluster, cluster_array, cordinate_array[indices_of_cluster], \n",
    "                    zone_array[indices_of_cluster], data_array[indices_of_cluster], child_conn,))\n",
    "        \n",
    "        processes.append(process)\n",
    "        \n",
    "    for process in processes:\n",
    "        process.start()\n",
    "    \n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    \n",
    "    only_cluster_centers = []\n",
    "    for parent_connection in parent_connections:\n",
    "        cluster = parent_connection.recv()\n",
    "        return_value.append(cluster) #[0]\n",
    "        only_cluster_centers.append([cluster['cluster_latitude'], cluster['cluster_longitude']])\n",
    "\n",
    "    # get all the cluster center locations and all the pole locations\n",
    "    # get the closest pole for each of the cluster\n",
    "    # update the pole number in each of the cluster as a new closest_pole_number attribute\n",
    "    poles = []\n",
    "    \n",
    "    for d in poles_data:\n",
    "        poles.append([d['latitude'], d['longitude']])\n",
    "    \n",
    "    poles = np.array(poles)\n",
    "    \n",
    "    only_cluster_centers = np.array(only_cluster_centers)\n",
    "\n",
    "    result = haversine_distances(np.radians(only_cluster_centers), np.radians(poles))\n",
    "    nearest_pole_manual_id = (result.argmin(axis=1, ) + 1).tolist()\n",
    "    print(\"Pole errors\", result.min(axis=1)*6371000)\n",
    "    print(\"Mean pole errors\", result.min(axis=1).mean()*6371000)\n",
    "    print(\"Max pole error\", result.min(axis=1).max()*6371000)\n",
    "    for index, cluster in enumerate(return_value):\n",
    "        cluster['nearest_pole'] = nearest_pole_manual_id[index]\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": {'objects': return_value}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodness(b1=50, b2=100, p=100):\n",
    "    results = lambda_handler(b1=b1, b2=b2,p=p)['body']['objects']\n",
    "    cluster_centers = [[cluster['cluster_latitude'], cluster['cluster_longitude']]for cluster in results]\n",
    "    cluster_centers = np.array(cluster_centers)\n",
    "    \n",
    "    json_data = open('data_ver3.json') \n",
    "    data = json.load(json_data)['data']\n",
    "    collected_data = [[d['latitude'], d['longitude']] for d in data]\n",
    "    collected_data = np.array(collected_data)\n",
    "    json_data.close()\n",
    "    \n",
    "    true_data = [[29.70154390339952, -95.39209601022654],[29.70428338419638, -95.39100648039813], [29.703335743447496, -95.39130824050142], [29.702188761458533, -95.3936918414558], [29.702691697389692, -95.39530032710667], [29.703085520490866, -95.39629883360872], [29.722233773075338, -95.36705220231357],[29.72526628586194, -95.37240452291601], [29.72734309820575, -95.375255487577], [29.728189612898646, -95.37701142524726],[29.729725295675568, -95.38003134004325], [29.73117267948174, -95.38260255498517],[29.731857687219605, -95.38404510951365],[29.756970123575087, -95.37525775033865], [29.7552538566023, -95.37571750526642],[29.755200480497276, -95.3794874504529],[29.75464650875399, -95.38024579642178],[29.754603020003177, -95.38300456681712],[29.752629019819906, -95.38306070220811], [29.752095895517666, -95.38491481879633]]\n",
    "    true_data = np.array(true_data)\n",
    "    \n",
    "    return collected_data, cluster_centers, true_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Error(b1=50, b2=150, p=100, print_data = True):\n",
    "    collected_data, cluster_centers, true_data = goodness(b1, b2, p)\n",
    "    radians_in_m = 6371000\n",
    "    result = haversine_distances(np.radians(true_data), np.radians(cluster_centers)) * radians_in_m\n",
    "    min_distances = result.min(axis=1)\n",
    "    print(\"Min distances \", min_distances)\n",
    "    \n",
    "    new_cluster_center = cluster_centers[np.argmin(result, axis=1)]\n",
    "    mean = min_distances.mean()\n",
    "    maxim = min_distances.max()\n",
    "    if print_data:\n",
    "        print(\"Mean error is {}m\".format(mean))\n",
    "        print(\"Maximum error is {}m\".format(maxim))\n",
    "    return mean, maxim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pole errors [15.42430175 19.4592518  44.83437874  9.16294583 71.55319174  5.23516925\n",
      "  6.50281922  3.61947334  7.7617927  12.18258267  6.37746913 13.01331268\n",
      "  4.36511677 26.8142986  12.34307113 14.2379882  26.14501983  5.23800575\n",
      " 10.21548424 37.57675737]\n",
      "Mean pole errors 17.603121537274866\n",
      "Max pole error 71.55319173810241\n",
      "Min distances  [ 4.70139147  3.69329973  3.8878708   4.63681103  3.19171568  5.16559677\n",
      "  1.85820794  9.28243535  5.55476928 11.54327371  4.31383105  4.54097628\n",
      "  1.39203835  4.40669808  2.61441637  5.53343948  3.03353469  3.09634655\n",
      "  2.00183442  2.10752166]\n",
      "Mean error is 4.327800435561568m\n",
      "Maximum error is 11.543273705780168m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.327800435561568, 11.543273705780168)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_Error(50,150,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
