{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift\n",
    "import utm\n",
    "from sklearn.cluster import MeanShift\n",
    "import statistics \n",
    "from statistics import mode \n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import geocoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Process, Pipe\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel(cluster_id, cluster_array,cordinate_array, zone_array, data_array, conn):\n",
    "    current_cluster_result = {}\n",
    "    \n",
    "    len_of_cluster = len(cluster_array)\n",
    "    compass_array = cluster_array[:,[2]]\n",
    "    a = np.tan(np.radians(90-compass_array))\n",
    "    b = np.ones(np.shape(compass_array))\n",
    "    c = np.multiply(a,cluster_array[:,[0]]) - cluster_array[:,[1]]\n",
    "    eq_coeff_cluster = np.hstack((a, -b ,c))\n",
    "    # we take the value of p as 300 just for analysing the time taken to run this\n",
    "    # Creating lines from the compass and the current point\n",
    "    p = 200\n",
    "\n",
    "    # Initializing the intersection of lines numpy array\n",
    "    pairwise_indices = np.random.randint(0, len_of_cluster , (p,2))\n",
    "    pairs = eq_coeff_cluster[pairwise_indices]\n",
    "\n",
    "    A = pairs[:,:,:-1]\n",
    "    Y = pairs[:,:,-1:]\n",
    "    intersections_of_lines = np.squeeze(np.matmul(np.linalg.pinv(A),  Y))\n",
    "    ms = MeanShift(bandwidth=150)  \n",
    "    labels = (ms.fit_predict(intersections_of_lines)).tolist()\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "    end = time.time()\n",
    "\n",
    "    mode_of_labels = max(set(labels), key=labels.count)\n",
    "    current_cluster_result['cluster_id'] = cluster_id\n",
    "    current_cluster_result['cluster_item_count'] = len_of_cluster       \n",
    "    \n",
    "    cordinate_list = (cordinate_array).tolist()\n",
    "    cordinate = max(set(cordinate_list), key=cordinate_list.count)\n",
    "\n",
    "    zone_list = (zone_array).tolist()\n",
    "    zone = max(set(zone_list), key=zone_list.count)\n",
    "    lat_long = utm.to_latlon(cluster_centers[mode_of_labels][0], cluster_centers[mode_of_labels][1], cordinate, zone)\n",
    "\n",
    "    current_cluster_result['cluster_latitude'] = lat_long[0]\n",
    "    current_cluster_result['cluster_longitude'] = lat_long[1]\n",
    "    current_cluster_result['cluster_objects'] = (data_array).tolist()\n",
    "    conn.send(current_cluster_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure dt\n",
    "def lambda_handler(b1 = 50, b2 = 150, p = 250):\n",
    "    with open('data_ver3.json') as json_data:\n",
    "        \n",
    "        data = json.load(json_data)['data']\n",
    "        array = []\n",
    "        # Creating image array which contains all the images\n",
    "        data_array = []\n",
    "        # Creating a cordinate array which contains all the coordinates\n",
    "        cordinate_array = []\n",
    "\n",
    "        zone_array = []\n",
    "\n",
    "        #add magnetic declination adjustment in College Station = 2.85°, in Houston = 2.28°\n",
    "        \n",
    "        for d in data:\n",
    "            ut_cordinates = utm.from_latlon(d['latitude'], d['longitude'])\n",
    "            t_list = [ut_cordinates[0],ut_cordinates[1],d['compass']+2.28]\n",
    "            data_array.append(d)\n",
    "            cordinate_array.append(ut_cordinates[2])\n",
    "            zone_array.append(ut_cordinates[3])\n",
    "            array.append(t_list)\n",
    "        array = np.array(array)\n",
    "        data_array = np.array(data_array)\n",
    "        cordinate_array = np.array(cordinate_array)\n",
    "        zone_array = np.array(zone_array)\n",
    "        \n",
    "        \n",
    "        # Now the array will have latitude, longitude and compass as its columns\n",
    "        X = array[:,[0,1]]\n",
    "        # Now X will have only latitude and longitude values. Performing mean shift algorithm on the latitude and longitudes\n",
    "        ms = MeanShift(bandwidth=b1)\n",
    "        labels = ms.fit_predict(X)\n",
    "        cluster_centers = ms.cluster_centers_\n",
    "        labels = np.vstack(labels)\n",
    "\n",
    "        array = np.hstack((array,labels))\n",
    "        # Stacking the labels next to array. Now array contains latitude, longitude, compass, label\n",
    "        \n",
    "        return_value = []\n",
    "        processes = []\n",
    "        parent_connections = []\n",
    "        \n",
    "        for cluster in range(len(cluster_centers)):\n",
    "            \n",
    "            indices_of_cluster = np.where(array[:,3] == cluster)\n",
    "            cluster_array = array[indices_of_cluster]  \n",
    "            len_of_cluster = len(cluster_array)\n",
    "            if len_of_cluster < 2:\n",
    "                continue\n",
    "            parent_conn, child_conn = Pipe()\n",
    "            parent_connections.append(parent_conn)\n",
    "            \n",
    "            process = Process(target=parallel, args=(cluster, cluster_array, cordinate_array[indices_of_cluster], \n",
    "                     zone_array[indices_of_cluster], data_array[indices_of_cluster], child_conn,))\n",
    "            \n",
    "            processes.append(process)\n",
    "            \n",
    "        for process in processes:\n",
    "            process.start()\n",
    "        \n",
    "        for process in processes:\n",
    "            process.join()\n",
    "        \n",
    "        for parent_connection in parent_connections:\n",
    "            return_value.append(parent_connection.recv()) #[0]\n",
    "            \n",
    "        return {\n",
    "            \"statusCode\": 200,\n",
    "            \"body\": json.dumps({'objects': return_value})\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621.0441589355469\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lambda_handler()\n",
    "end = time.time()\n",
    "print((end-start)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
